{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE8TCzZAOBjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bba0df1-8fba-488c-98f9-405a025526bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSzEzkNa9xY4"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "from os import path\n",
        "import librosa as lb\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "import csv\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaA3o-k5Nt0H"
      },
      "source": [
        "# Set your drive's path for the files used.\n",
        "maleVoicePath = '/content/drive/My Drive/ML Project/male'\n",
        "whiteNoisePath = '/content/drive/My Drive/ML Project/whitenoise'\n",
        "DrivePath = '/content/drive/My Drive/ML Project'\n",
        "csvPath = '/content/drive/My Drive/ML Project/data.csv'\n",
        "numMaleFiles = 2715\n",
        "limit = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7l1Zo0JOpFW"
      },
      "source": [
        "# Static Variables for audio information\n",
        "windowLength = 256\n",
        "overlap      = round(0.25 * windowLength) # overlap of 75%\n",
        "ffTLength    = windowLength\n",
        "inputFs      = 48e3\n",
        "fs           = 16e3\n",
        "numFeatures  = ffTLength//2 + 1\n",
        "numSegments  = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfngH2kaWz0c"
      },
      "source": [
        "class FeatureExtractor:\n",
        "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
        "        self.audio = audio\n",
        "        self.ffT_length = windowLength\n",
        "        self.window_length = windowLength\n",
        "        self.overlap = overlap\n",
        "        self.sample_rate = sample_rate\n",
        "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
        "\n",
        "    def get_stft_spectrogram(self):\n",
        "        return lb.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
        "                            window=self.window, center=True)\n",
        "\n",
        "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
        "        return lb.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
        "                             window=self.window, center=True)\n",
        "\n",
        "    def get_mel_spectrogram(self):\n",
        "        return lb.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, n_fft=self.ffT_length, hop_length=self.overlap)\n",
        "\n",
        "    def get_audio_from_mel_spectrogram(self, M):\n",
        "        return lb.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n",
        "                                             win_length=self.window_length, window=self.window,\n",
        "                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHTcwRNwPDf1"
      },
      "source": [
        "# Source: https://github.com/daitan-innovation/cnn-audio-denoiser/blob/master/SpeechDenoiserCNN.ipynb\n",
        "def read_audio(filepath, sample_rate, normalize=True):\n",
        "    \"\"\"Read an audio file and return it as a numpy array\"\"\"\n",
        "    audio, sr = lb.load(filepath, sr=sample_rate)\n",
        "    if normalize:\n",
        "      div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
        "      audio = audio * div_fac\n",
        "    return audio, sr\n",
        "        \n",
        "def add_noise_to_clean_audio(clean_audio, noise_signal):\n",
        "    \"\"\"Adds noise to an audio sample\"\"\"\n",
        "    if len(clean_audio) >= len(noise_signal):\n",
        "        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n",
        "        while len(clean_audio) >= len(noise_signal):\n",
        "            noise_signal = np.append(noise_signal, noise_signal)\n",
        "\n",
        "    ## Extract a noise segment from a random location in the noise file\n",
        "    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
        "\n",
        "    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
        "\n",
        "    speech_power = np.sum(clean_audio ** 2)\n",
        "    noise_power = np.sum(noiseSegment ** 2)\n",
        "    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
        "    return noisyAudio\n",
        "\n",
        "def play(audio, sample_rate):\n",
        "    ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHGuIElCvZil"
      },
      "source": [
        "**Code to grab an array of all voices**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHWheZtP9y3Z"
      },
      "source": [
        "os.chdir(maleVoicePath) # changes the directory to the one holding the male clips\n",
        "Mypath = os.getcwd() # gets the directory\n",
        "Mypath = Mypath + '/' # adds a slash at the end\n",
        "all_sounds = []\n",
        "name = []\n",
        "entries = Path(Mypath) # gets all the files in the directory\n",
        "for files in entries.iterdir():\n",
        "  name.append(files.name) # gets the names of each file\n",
        "\n",
        "'''for index in range(len(os.listdir(path))):\n",
        "   #Use a smaller list for testing.'''\n",
        "\n",
        "for index in range(10):\n",
        "  y, sr = read_audio(Mypath + name[index], fs)\n",
        "  #lb.load(path + name[index]) # loads each file\n",
        "  all_sounds.append((y, sr)) # append to list for later use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwcg6xnqZi3N"
      },
      "source": [
        "os.chdir(whiteNoisePath)\n",
        "Mypath = os.getcwd()\n",
        "Mypath = Mypath + '/'\n",
        "entries = Path(Mypath)\n",
        "name = []\n",
        "all_whitenoise = []\n",
        "for files in entries.iterdir():\n",
        "  name.append(files.name)\n",
        "for index in range(len(os.listdir(Mypath))):\n",
        "  y, sr = read_audio(Mypath + name[index], fs)\n",
        "  all_whitenoise.append((y, sr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41tH5hmNmPbA"
      },
      "source": [
        "# code used from https://librosa.org/doc/latest/generated/librosa.stft.html\n",
        "#works with both types of sound, either sounds that have been split into their y, sr and those that have not\n",
        "def produce_stft_graph(sound, sr=1):\n",
        "  if not isinstance(sound, (np.ndarray)):\n",
        "    the_sound, sr = sound\n",
        "  else:\n",
        "    the_sound = sound\n",
        "    sr = sr\n",
        "\n",
        "  soundFeature = FeatureExtractor(the_sound, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
        "  abs_s = np.abs(soundFeature.get_stft_spectrogram())\n",
        "  fig, ax = plt.subplots()\n",
        "  img = lb.display.specshow(lb.amplitude_to_db(abs_s, ref=np.max), y_axis='log', x_axis='time', ax=ax)\n",
        "  ax.set_title('Power spectogram')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy4XV7ouMtzS"
      },
      "source": [
        "for sound in all_sounds:\n",
        "  x, y = sound\n",
        "  produce_stft_graph(sound)\n",
        "  #play(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk2IX-24aDDD"
      },
      "source": [
        "for sound in all_whitenoise:\n",
        "  x, y = sound\n",
        "  #play(x, y)\n",
        "  produce_stft_graph(sound)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaOxmwEaZGPI"
      },
      "source": [
        "test area for making the csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AgklSPQ5ej2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661168d2-4be1-4266-997c-5135b9dd960d"
      },
      "source": [
        "soundextractors = []\n",
        "for sound in all_sounds:\n",
        "  the_sound, sr = sound\n",
        "  soundextractors.append(FeatureExtractor(the_sound, windowLength=windowLength, overlap=overlap, sample_rate=sr))\n",
        "\n",
        "new = False\n",
        "\n",
        "os.chdir(DrivePath)\n",
        "if not path.exists('data.csv'):\n",
        "  new = True\n",
        "\n",
        "with open(\"data.csv\",\"w\") as file:\n",
        "  write = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "  if new:\n",
        "    write.writerow(['File', 'stft', 'mel', 'sample rate'])\n",
        "\n",
        "  for index, sound in enumerate(soundextractors):\n",
        "    file_path = whiteNoisePath + '/' + name[index]\n",
        "    stft = sound.get_stft_spectrogram()\n",
        "    mel = sound.get_mel_spectrogram()\n",
        "    samp_rate = sound.sample_rate\n",
        "\n",
        "    write.writerow([file_path, stft, mel, samp_rate])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl24WZ64Fa-E"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfkWwNa_h2dU"
      },
      "source": [
        "features = pd.read_csv(csvPath)\n",
        "features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0zjaKKvn19e"
      },
      "source": [
        "The code under here is heavily WIP and most doesn't work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZwLkifgYAtV"
      },
      "source": [
        "cleanAudio, sr = all_sounds[1]\n",
        "print(\"Min:\", np.min(cleanAudio),\"Max:\",np.max(cleanAudio))\n",
        "ipd.Audio(data=cleanAudio, rate=sr) # load a local WAV file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBsDN9cDnnt8"
      },
      "source": [
        "produce_stft_graph(sound = all_sounds[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esrdKfkFkkHM"
      },
      "source": [
        "produce_stft_graph(sound = cleanAudio, sr = sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4fAPFo7YG9b"
      },
      "source": [
        "noiseAudio, sr = all_whitenoise[0]\n",
        "print(\"Min:\", np.min(noiseAudio),\"Max:\",np.max(noiseAudio))\n",
        "ipd.Audio(data=noiseAudio, rate=sr) # load a local WAV file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgd_AsaDW87Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b9f4e0-a072-4859-aa38-88b1a0b53250"
      },
      "source": [
        "# Clean Audio Feature Extractor\n",
        "cleanAudioFeatureExtractor = FeatureExtractor(cleanAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
        "stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n",
        "stft_features = np.abs(stft_features)\n",
        "print(\"Min:\", np.min(stft_features),\"Max:\",np.max(stft_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min: 6.419848e-09 Max: 10.067297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiuW5N_hj2Jn"
      },
      "source": [
        "print(\"clean\")\n",
        "produce_stft_graph(cleanAudio)\n",
        "\n",
        "print(\"dirty\")\n",
        "produce_stft_graph(noiseAudio)\n",
        "\n",
        "noisyAudio = add_noise_to_clean_audio(cleanAudio, noiseAudio)\n",
        "ipd.Audio(data=noisyAudio, rate=fs) # load a local WAV file\n",
        "\n",
        "print(\"combined\")\n",
        "produce_stft_graph(noisyAudio)\n",
        "play(noisyAudio, fs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6VAr-1hYMYc"
      },
      "source": [
        "def prepare_input_features(stft_features):\n",
        "    # Phase Aware Scaling: To avoid extreme differences (more than\n",
        "    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n",
        "    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n",
        "    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n",
        "\n",
        "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
        "        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n",
        "    return stftSegments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyOJE83dXSq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db14b79c-018d-4885-dfb8-763d2ee921a2"
      },
      "source": [
        "noiseAudioFeatureExtractor = FeatureExtractor(noisyAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
        "noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n",
        "\n",
        "# Paper: Besides, spectral phase was not used in the training phase.\n",
        "# At reconstruction, noisy spectral phase was used instead to\n",
        "# perform in- verse STFT and recover human speech.\n",
        "noisyPhase = np.angle(noise_stft_features)\n",
        "print(noisyPhase.shape)\n",
        "noise_stft_features = np.abs(noise_stft_features)\n",
        "\n",
        "mean = np.mean(noise_stft_features)\n",
        "std = np.std(noise_stft_features)\n",
        "noise_stft_features = (noise_stft_features - mean) / std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(129, 1723)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i84fXgsfu_L4"
      },
      "source": [
        "Tensorflow Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hTY2PYnvOvO"
      },
      "source": [
        "path_to_dataset = \"./dataset/tfrecords\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFQvt9GOvHSH"
      },
      "source": [
        "# get training and validation tf record file names\n",
        "train_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'train_*'))\n",
        "val_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'val_*'))\n",
        "\n",
        "# suffle the file names for training\n",
        "np.random.shuffle(train_tfrecords_filenames)\n",
        "print(\"Training file names: \", train_tfrecords_filenames)\n",
        "print(\"Validation file names: \", val_tfrecords_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb10kX91vBsJ"
      },
      "source": [
        "train_dataset = tf.data.TFRecordDataset([train_tfrecords_filenames])\n",
        "train_dataset = train_dataset.map(tf_record_parser)\n",
        "train_dataset = train_dataset.shuffle(8192)\n",
        "train_dataset = train_dataset.repeat()\n",
        "train_dataset = train_dataset.batch(512)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRJcd0mqvEAe"
      },
      "source": [
        "test_dataset = tf.data.TFRecordDataset([val_tfrecords_filenames])\n",
        "test_dataset = test_dataset.map(tf_record_parser)\n",
        "test_dataset = test_dataset.repeat(1)\n",
        "test_dataset = test_dataset.batch(512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1lplwlTu8f2"
      },
      "source": [
        "Tensorflow Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffs8Nwj0u8B9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}