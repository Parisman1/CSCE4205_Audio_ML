{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "twZDkoA80o8e"
      },
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import math\n",
        "import multiprocessing\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy\n",
        "import pickle\n",
        "import IPython.display as ipd"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo9ACHKT0prf"
      },
      "source": [
        "np.random.seed(999)\n",
        "tf.random.set_seed(999)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDQW8Brk1OkH",
        "outputId": "57410d54-bf2f-43f9-d21e-239724784930"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8-LdUYy1OH1"
      },
      "source": [
        "# Set your drive's path for the files used.\n",
        "maleVoicePath = '/content/drive/My Drive/ML Project/.csv'\n",
        "whiteNoisePath = '/content/drive/My Drive/ML Project/.csv'\n",
        "DrivePath = '/content/drive/My Drive/ML Project'"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vt8kS0M0tTF"
      },
      "source": [
        "Utilities Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyLR9WXW0sU9"
      },
      "source": [
        "def inverse_stft_transform(stft_features, window_length, overlap):\n",
        "    return librosa.istft(stft_features, win_length=window_length, hop_length=overlap)\n",
        "\n",
        "def revert_features_to_audio(features, phase, window_length, overlap, cleanMean=None, cleanStd=None):\n",
        "    # scale the outpus back to the original range\n",
        "    if cleanMean and cleanStd:\n",
        "        features = cleanStd * features + cleanMean\n",
        "\n",
        "    phase = np.transpose(phase, (1, 0))\n",
        "    features = np.squeeze(features)\n",
        "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
        "\n",
        "    features = np.transpose(features, (1, 0))\n",
        "    return inverse_stft_transform(features, window_length=window_length, overlap=overlap)\n",
        "\n",
        "def play(audio, sample_rate):\n",
        "    ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file\n",
        "\n",
        "def add_noise_to_clean_audio(clean_audio, noise_signal):\n",
        "    if len(clean_audio) >= len(noise_signal):\n",
        "        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n",
        "        while len(clean_audio) >= len(noise_signal):\n",
        "            noise_signal = np.append(noise_signal, noise_signal)\n",
        "\n",
        "    ## Extract a noise segment from a random location in the noise file\n",
        "    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
        "\n",
        "    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
        "\n",
        "    speech_power = np.sum(clean_audio ** 2)\n",
        "    noise_power = np.sum(noiseSegment ** 2)\n",
        "    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
        "    return noisyAudio\n",
        "\n",
        "def read_audio(filepath, sample_rate, normalize=True):\n",
        "    audio, sr = librosa.load(filepath, sr=sample_rate)\n",
        "    if normalize is True:\n",
        "        div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
        "        audio = audio * div_fac\n",
        "        # audio = librosa.util.normalize(audio)\n",
        "    return audio, sr\n",
        "\n",
        "def prepare_input_features(stft_features, numSegments, numFeatures):\n",
        "    noisySTFT = np.concatenate([stft_features[:, 0:numSegments - 1], stft_features], axis=1)\n",
        "    stftSegments = np.zeros((numFeatures, numSegments, noisySTFT.shape[1] - numSegments + 1))\n",
        "\n",
        "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
        "        stftSegments[:, :, index] = noisySTFT[:, index:index + numSegments]\n",
        "    return stftSegments\n",
        "'''\n",
        "def get_input_features(predictorsList):\n",
        "    predictors = []\n",
        "    for noisy_stft_mag_features in predictorsList:\n",
        "        # For CNN, the input feature consisted of 8 consecutive noisy\n",
        "        # STFT magnitude vectors of size: 129 Ã— 8,\n",
        "        # TODO: duration: 100ms\n",
        "        inputFeatures = prepare_input_features(noisy_stft_mag_features)\n",
        "        # print(\"inputFeatures.shape\", inputFeatures.shape)\n",
        "        predictors.append(inputFeatures)\n",
        "    return predictors\n",
        "'''\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def get_tf_feature(noise_stft_mag_features, clean_stft_magnitude, noise_stft_phase):\n",
        "    noise_stft_mag_features = noise_stft_mag_features.astype(np.float32).tostring()\n",
        "    clean_stft_magnitude = clean_stft_magnitude.astype(np.float32).tostring()\n",
        "    noise_stft_phase = noise_stft_phase.astype(np.float32).tostring()\n",
        "\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'noise_stft_phase': _bytes_feature(noise_stft_phase),\n",
        "        'noise_stft_mag_features': _bytes_feature(noise_stft_mag_features),\n",
        "        'clean_stft_magnitude': _bytes_feature(clean_stft_magnitude)}))\n",
        "    return example\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOxIstrR0u13"
      },
      "source": [
        "Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS20ZPpm0v8C"
      },
      "source": [
        "class FeatureExtractor:\n",
        "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
        "        self.audio = audio\n",
        "        self.ffT_length = windowLength\n",
        "        self.window_length = windowLength\n",
        "        self.overlap = overlap\n",
        "        self.sample_rate = sample_rate\n",
        "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
        "\n",
        "    def get_stft_spectrogram(self):\n",
        "        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
        "                            window=self.window, center=True)\n",
        "\n",
        "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
        "        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
        "                             window=self.window, center=True)\n",
        "\n",
        "    def get_mel_spectrogram(self):\n",
        "        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n",
        "                                              n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n",
        "\n",
        "    def get_audio_from_mel_spectrogram(self, M):\n",
        "        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length,\n",
        "                                                    hop_length=self.overlap,\n",
        "                                                    win_length=self.window_length, window=self.window,\n",
        "                                                    center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jiYK7240zTy"
      },
      "source": [
        "Base Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd1I7fj40y7d"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, clean_filenames, noise_filenames, **config):\n",
        "        self.clean_filenames = clean_filenames\n",
        "        self.noise_filenames = noise_filenames\n",
        "        self.sample_rate = config['fs']\n",
        "        self.overlap = config['overlap']\n",
        "        self.window_length = config['windowLength']\n",
        "        self.audio_max_duration = config['audio_max_duration']\n",
        "\n",
        "    def _sample_noise_filename(self):\n",
        "        return np.random.choice(self.noise_filenames)\n",
        "\n",
        "    def _remove_silent_frames(self, audio):\n",
        "        trimed_audio = []\n",
        "        indices = librosa.effects.split(audio, hop_length=self.overlap, top_db=20)\n",
        "\n",
        "        for index in indices:\n",
        "            trimed_audio.extend(audio[index[0]: index[1]])\n",
        "        return np.array(trimed_audio)\n",
        "\n",
        "    def _phase_aware_scaling(self, clean_spectral_magnitude, clean_phase, noise_phase):\n",
        "        assert clean_phase.shape == noise_phase.shape, \"Shapes must match.\"\n",
        "        return clean_spectral_magnitude * np.cos(clean_phase - noise_phase)\n",
        "\n",
        "    def get_noisy_audio(self, *, filename):\n",
        "        return read_audio(filename, self.sample_rate)\n",
        "\n",
        "    def _audio_random_crop(self, audio, duration):\n",
        "        audio_duration_secs = librosa.core.get_duration(audio, self.sample_rate)\n",
        "\n",
        "        ## duration: length of the cropped audio in seconds\n",
        "        if duration >= audio_duration_secs:\n",
        "            # print(\"Passed duration greater than audio duration of: \", audio_duration_secs)\n",
        "            return audio\n",
        "\n",
        "        audio_duration_ms = math.floor(audio_duration_secs * self.sample_rate)\n",
        "        duration_ms = math.floor(duration * self.sample_rate)\n",
        "        idx = np.random.randint(0, audio_duration_ms - duration_ms)\n",
        "        return audio[idx: idx + duration_ms]\n",
        "\n",
        "    def _add_noise_to_clean_audio(self, clean_audio, noise_signal):\n",
        "        if len(clean_audio) >= len(noise_signal):\n",
        "            # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n",
        "            while len(clean_audio) >= len(noise_signal):\n",
        "                noise_signal = np.append(noise_signal, noise_signal)\n",
        "\n",
        "        ## Extract a noise segment from a random location in the noise file\n",
        "        ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
        "\n",
        "        noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
        "\n",
        "        speech_power = np.sum(clean_audio ** 2)\n",
        "        noise_power = np.sum(noiseSegment ** 2)\n",
        "        noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
        "        return noisyAudio\n",
        "\n",
        "    def parallel_audio_processing(self, clean_filename):\n",
        "        print(\"Entered parallel_audio_processing\")\n",
        "        clean_audio, _ = read_audio(clean_filename, self.sample_rate)\n",
        "\n",
        "        # remove silent frame from clean audio\n",
        "        clean_audio = self._remove_silent_frames(clean_audio)\n",
        "\n",
        "        noise_filename = self._sample_noise_filename()\n",
        "\n",
        "        # read the noise filename\n",
        "        noise_audio, sr = read_audio(noise_filename, self.sample_rate)\n",
        "\n",
        "        # remove silent frame from noise audio\n",
        "        noise_audio = self._remove_silent_frames(noise_audio)\n",
        "\n",
        "        # sample random fixed-sized snippets of audio\n",
        "        clean_audio = self._audio_random_crop(clean_audio, duration=self.audio_max_duration)\n",
        "\n",
        "        # add noise to input image\n",
        "        noiseInput = self._add_noise_to_clean_audio(clean_audio, noise_audio)\n",
        "\n",
        "        # extract stft features from noisy audio\n",
        "        noisy_input_fe = FeatureExtractor(noiseInput, windowLength=self.window_length, overlap=self.overlap,\n",
        "                                          sample_rate=self.sample_rate)\n",
        "        noise_spectrogram = noisy_input_fe.get_stft_spectrogram()\n",
        "\n",
        "        # Or get the phase angle (in radians)\n",
        "        # noisy_stft_magnitude, noisy_stft_phase = librosa.magphase(noisy_stft_features)\n",
        "        noise_phase = np.angle(noise_spectrogram)\n",
        "\n",
        "        # get the magnitude of the spectral\n",
        "        noise_magnitude = np.abs(noise_spectrogram)\n",
        "\n",
        "        # extract stft features from clean audio\n",
        "        clean_audio_fe = FeatureExtractor(clean_audio, windowLength=self.window_length, overlap=self.overlap,\n",
        "                                          sample_rate=self.sample_rate)\n",
        "        clean_spectrogram = clean_audio_fe.get_stft_spectrogram()\n",
        "        # clean_spectrogram = cleanAudioFE.get_mel_spectrogram()\n",
        "\n",
        "        # get the clean phase\n",
        "        clean_phase = np.angle(clean_spectrogram)\n",
        "\n",
        "        # get the clean spectral magnitude\n",
        "        clean_magnitude = np.abs(clean_spectrogram)\n",
        "        # clean_magnitude = 2 * clean_magnitude / np.sum(scipy.signal.hamming(self.window_length, sym=False))\n",
        "\n",
        "        clean_magnitude = self._phase_aware_scaling(clean_magnitude, clean_phase, noise_phase)\n",
        "\n",
        "        scaler = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
        "        noise_magnitude = scaler.fit_transform(noise_magnitude)\n",
        "        clean_magnitude = scaler.transform(clean_magnitude)\n",
        "\n",
        "        return noise_magnitude, clean_magnitude, noise_phase\n",
        "\n",
        "    def create_tf_record(self, *, prefix, subset_size, parallel=True):\n",
        "        counter = 0\n",
        "        p = multiprocessing.Pool(multiprocessing.cpu_count())\n",
        "\n",
        "        for i in range(0, len(self.clean_filenames), subset_size):\n",
        "\n",
        "            #tfrecord_filename = './records/' + prefix + '_' + str(counter) + '.tfrecords'\n",
        "            tfrecord_filename = '/content/drive/My Drive/ML Project/records/' + prefix + '_' + str(counter) + '.tfrecords'\n",
        "            if os.path.isfile(tfrecord_filename):\n",
        "                print(f\"Skipping {tfrecord_filename}\")\n",
        "                counter += 1\n",
        "                continue\n",
        "\n",
        "            writer = tf.io.TFRecordWriter(tfrecord_filename)\n",
        "            clean_filenames_sublist = self.clean_filenames[i:i + subset_size]\n",
        "\n",
        "            print(f\"Processing files from: {i} to {i + subset_size}\")\n",
        "            if parallel:\n",
        "                print(\"parallel\")\n",
        "                out = p.map(self.parallel_audio_processing, clean_filenames_sublist)\n",
        "                print(\"out of map\")\n",
        "            else:\n",
        "                print(\"out\")\n",
        "                out = [self.parallel_audio_processing(filename) for filename in clean_filenames_sublist]\n",
        "            print(\"pre o in out\")\n",
        "            for o in out:\n",
        "                print(\"Check o in out\")\n",
        "                noise_stft_magnitude = o[0]\n",
        "                clean_stft_magnitude = o[1]\n",
        "                noise_stft_phase = o[2]\n",
        "\n",
        "                noise_stft_mag_features = prepare_input_features(noise_stft_magnitude, numSegments=8, numFeatures=129)\n",
        "\n",
        "                noise_stft_mag_features = np.transpose(noise_stft_mag_features, (2, 0, 1))\n",
        "                clean_stft_magnitude = np.transpose(clean_stft_magnitude, (1, 0))\n",
        "                noise_stft_phase = np.transpose(noise_stft_phase, (1, 0))\n",
        "\n",
        "                noise_stft_mag_features = np.expand_dims(noise_stft_mag_features, axis=3)\n",
        "                clean_stft_magnitude = np.expand_dims(clean_stft_magnitude, axis=2)\n",
        "\n",
        "                for x_, y_, p_ in zip(noise_stft_mag_features, clean_stft_magnitude, noise_stft_phase):\n",
        "                    print(\"Check xyp\")\n",
        "                    y_ = np.expand_dims(y_, 2)\n",
        "                    example = get_tf_feature(x_, y_, p_)\n",
        "                    writer.write(example.SerializeToString())\n",
        "\n",
        "            counter += 1\n",
        "            writer.close()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N1NzjXu04LQ"
      },
      "source": [
        "Common Voice Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlKYKAKY04wk"
      },
      "source": [
        "class MozillaCommonVoiceDataset:\n",
        "\n",
        "    def __init__(self, basepath, *, val_dataset_size):\n",
        "        self.basepath = basepath\n",
        "        self.val_dataset_size = val_dataset_size\n",
        "\n",
        "    def _get_common_voice_filenames(self, dataframe_name='male.csv'):\n",
        "        mozilla_metadata = pd.read_csv(os.path.join(self.basepath, dataframe_name))\n",
        "        clean_files = mozilla_metadata['File'].values\n",
        "        np.random.shuffle(clean_files)\n",
        "        print(\"Total number of training examples:\", len(clean_files))\n",
        "        return clean_files\n",
        "\n",
        "    def get_train_val_filenames(self):\n",
        "        clean_files = self._get_common_voice_filenames(dataframe_name='male.csv')\n",
        "\n",
        "        # resolve full path\n",
        "        clean_files = [os.path.join(DrivePath, 'male', filename) for filename in clean_files]\n",
        "        #'/content/drive/My Drive/ML Project/.csv/clips/test/common_voice_en_22238323.mp3\n",
        "        clean_files = clean_files[:-self.val_dataset_size]\n",
        "        clean_val_files = clean_files[-self.val_dataset_size:]\n",
        "        print(\"# of Training clean files:\", len(clean_files))\n",
        "        print(\"# of  Validation clean files:\", len(clean_val_files))\n",
        "        return clean_files, clean_val_files\n",
        "\n",
        "\n",
        "    def get_test_filenames(self):\n",
        "        clean_files = self._get_common_voice_filenames(dataframe_name='male.csv')\n",
        "\n",
        "        # resolve full path\n",
        "        clean_files = [os.path.join(DrivePath, 'male', filename) for filename in clean_files]\n",
        "\n",
        "        print(\"# of Testing clean files:\", len(clean_files))\n",
        "        return clean_files"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmB_2BUm07XW"
      },
      "source": [
        "WhiteNoise Class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU76tEZE076n"
      },
      "source": [
        "class WhiteNoise:\n",
        "    def __init__(self, basepath, *, val_dataset_size, class_ids=None):\n",
        "        self.basepath = basepath\n",
        "        self.val_dataset_size = val_dataset_size\n",
        "        self.class_ids = class_ids\n",
        "\n",
        "    def _get_whitenoise_filenames(self):\n",
        "        whitenoise_metadata = pd.read_csv(os.path.join(self.basepath, 'WhiteNoise.csv'))\n",
        "\n",
        "        # shuffle the dataframe\n",
        "        whitenoise_metadata.reindex(np.random.permutation(whitenoise_metadata.index))\n",
        "\n",
        "        return whitenoise_metadata\n",
        "\n",
        "    def _get_filenames_by_class_id(self, metadata):\n",
        "\n",
        "        if self.class_ids is None:\n",
        "            self.class_ids = np.unique(metadata['classID'].values)\n",
        "            print(\"Number of classes:\", self.class_ids)\n",
        "\n",
        "        all_files = []\n",
        "        file_counter = 0\n",
        "        for c in self.class_ids:\n",
        "            per_class_files = metadata[metadata['classID'] == c][['slice_file_name', 'fold']].values\n",
        "            per_class_files = [os.path.join(self.basepath, 'audio', 'fold' + str(file[1]), file[0]) for file in\n",
        "                               per_class_files]\n",
        "            print(\"Class c:\", str(c), 'has:', len(per_class_files), 'files')\n",
        "            file_counter += len(per_class_files)\n",
        "            all_files.extend(per_class_files)\n",
        "\n",
        "        assert len(all_files) == file_counter\n",
        "        return all_files\n",
        "\n",
        "    def get_train_val_filenames(self):\n",
        "        whitenoise_metadata = self._get_whitenoise_filenames()\n",
        "        '''\n",
        "        # folds from 0 to 9 are used for training\n",
        "        whitenoise_train = whitenoise_metadata[whitenoise_metadata.fold != 10]\n",
        "\n",
        "        whitenoise_train_filenames = self._get_filenames_by_class_id(whitenoise_train)\n",
        "        np.random.shuffle(whitenoise_train_filenames)\n",
        "        '''\n",
        "        # separate noise files for train/validation\n",
        "        whitenoise_train_filenames = whitenoise_metadata['File'].values\n",
        "        np.random.shuffle(whitenoise_train_filenames)\n",
        "\n",
        "        whitenoise_val = whitenoise_train_filenames[-self.val_dataset_size:]\n",
        "        whitenoise_train = whitenoise_train_filenames[:-self.val_dataset_size]\n",
        "\n",
        "        return whitenoise_train, whitenoise_val\n",
        "\n",
        "    def get_test_filenames(self):\n",
        "        whitenoise_metadata = self._get_whitenoise_filenames()\n",
        "        whitenoise_test_filenames = whitenoise_metadata['File'].values\n",
        "        '''\n",
        "        # fold 10 is used for testing only\n",
        "        whitenoise_train = whitenoise_metadata[whitenoise_metadata.fold == 10]\n",
        "        '''\n",
        "        #whitenoise_test_filenames = self._get_filenames_by_class_id(whitenoise_train)\n",
        "        np.random.shuffle(whitenoise_test_filenames)\n",
        "\n",
        "        print(\"# of Noise testing files:\", len(whitenoise_test_filenames))\n",
        "        return whitenoise_test_filenames"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vHlIc6a0_Ya"
      },
      "source": [
        "Final Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-GmrL60lL9"
      },
      "source": [
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "mozilla_basepath = maleVoicePath\n",
        "whitenoise_basepath = whiteNoisePath\n",
        "\n",
        "mcv = MozillaCommonVoiceDataset(mozilla_basepath, val_dataset_size=500)\n",
        "clean_train_filenames, clean_val_filenames = mcv.get_train_val_filenames()\n",
        "\n",
        "wn = WhiteNoise(whitenoise_basepath, val_dataset_size=5)\n",
        "noise_train_filenames, noise_val_filenames = wn.get_train_val_filenames()\n",
        "\n",
        "windowLength = 256\n",
        "config = {'windowLength': windowLength,\n",
        "          'overlap': round(0.25 * windowLength),\n",
        "          'fs': 16000,\n",
        "          'audio_max_duration': 0.8}\n",
        "print(noise_val_filenames)\n",
        "val_dataset = Dataset(clean_val_filenames, noise_val_filenames, **config)\n",
        "val_dataset.create_tf_record(prefix='val', subset_size=30)\n",
        "\n",
        "train_dataset = Dataset(clean_train_filenames, noise_train_filenames, **config)\n",
        "train_dataset.create_tf_record(prefix='train', subset_size=50)\n",
        "\n",
        "## Create Test Set\n",
        "clean_test_filenames = mcv.get_test_filenames()\n",
        "\n",
        "noise_test_filenames = wn.get_test_filenames()\n",
        "\n",
        "test_dataset = Dataset(clean_test_filenames, noise_test_filenames, **config)\n",
        "test_dataset.create_tf_record(prefix='test', subset_size=10, parallel=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}